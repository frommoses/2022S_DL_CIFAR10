{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c786a2e-6ce6-49b1-b6c0-21df5851d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-pdjn7dsd because the default path (/home/khc/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6dad46-5fb0-40f6-97d8-e502816159f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "#for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "seed = 777\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed_all(seed) #if use multi-GPU\n",
    "    #torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb419305-5d75-441f-8e1b-4d1e878d4c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "#start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.004\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_models'\n",
    "\n",
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224, padding=16),               # Random Position Crop\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "#mean=(0.4914, 0.4824, 0.4467)\n",
    "#std=(0.2471, 0.2436, 0.2616)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
    "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "#automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30d8401-820e-47bb-a761-d3defa7fe6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = models.resnext50_32x4d(pretrained=True)\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4,\n",
    "                                nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a3b44-8958-48c4-a07e-553d809e2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch_idx: 0 |  Loss: (9.1844) | Acc: (0.00%) (0/128)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (1.0313) | Acc: (74.31%) (9607/12928)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (0.6773) | Acc: (81.62%) (20999/25728)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (0.5334) | Acc: (85.01%) (32753/38528)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1582) | Acc: (94.62%) (9462/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (0.1223) | Acc: (96.09%) (123/128)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (0.1476) | Acc: (94.87%) (12265/12928)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (0.1460) | Acc: (94.99%) (24439/25728)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (0.1469) | Acc: (94.95%) (36583/38528)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1259) | Acc: (95.49%) (9549/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (0.0974) | Acc: (95.31%) (122/128)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (0.0846) | Acc: (97.01%) (12541/12928)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (0.0907) | Acc: (96.78%) (24899/25728)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (0.0892) | Acc: (96.92%) (37342/38528)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1219) | Acc: (95.94%) (9594/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (0.0321) | Acc: (99.22%) (127/128)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (0.0631) | Acc: (97.76%) (12638/12928)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (0.0620) | Acc: (97.81%) (25164/25728)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (0.0652) | Acc: (97.72%) (37651/38528)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1209) | Acc: (96.23%) (9623/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.0400) | Acc: (99.22%) (127/128)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (0.0510) | Acc: (98.22%) (12698/12928)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (0.0523) | Acc: (98.16%) (25254/25728)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (0.0519) | Acc: (98.15%) (37816/38528)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1269) | Acc: (96.09%) (9609/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.0644) | Acc: (97.66%) (125/128)\n"
     ]
    }
   ],
   "source": [
    "loss_l = []\n",
    "acc_l = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        loss_ = train_loss / (batch_idx + 1)\n",
    "        loss_l.append(loss_)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, loss_, 100. * correct / total, correct, total))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        acc_ = correct / total\n",
    "        acc_l.append(acc_)\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * acc_, correct, total))\n",
    "\n",
    "def save_checkpoint(directory, state, filename=str(learning_rate)+'latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename=str(learning_rate)+'latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 80):\n",
    "\n",
    "    if epoch < 50:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 65:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd2abe-86f1-4178-b7ba-2af514e7ef95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
